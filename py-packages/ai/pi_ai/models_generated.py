"""
Auto-generated model definitions.

This file is auto-generated. Do not edit manually.
"""

from __future__ import annotations

from typing import Any

# Sample model definitions - in production this would be generated
MODELS: dict[str, dict[str, dict[str, Any]]] = {
    "anthropic": {
        "claude-3-5-sonnet-20241022": {
            "id": "claude-3-5-sonnet-20241022",
            "name": "Claude 3.5 Sonnet",
            "api": "anthropic-messages",
            "provider": "anthropic",
            "base_url": "https://api.anthropic.com",
            "reasoning": False,
            "input": ["text", "image"],
            "cost": {
                "input": 3.0,
                "output": 15.0,
                "cache_read": 0.3,
                "cache_write": 3.75,
            },
            "context_window": 200000,
            "max_tokens": 8192,
        },
        "claude-3-5-haiku-20241022": {
            "id": "claude-3-5-haiku-20241022",
            "name": "Claude 3.5 Haiku",
            "api": "anthropic-messages",
            "provider": "anthropic",
            "base_url": "https://api.anthropic.com",
            "reasoning": False,
            "input": ["text", "image"],
            "cost": {
                "input": 0.8,
                "output": 4.0,
                "cache_read": 0.08,
                "cache_write": 1.0,
            },
            "context_window": 200000,
            "max_tokens": 8192,
        },
        "claude-sonnet-4-20250514": {
            "id": "claude-sonnet-4-20250514",
            "name": "Claude Sonnet 4",
            "api": "anthropic-messages",
            "provider": "anthropic",
            "base_url": "https://api.anthropic.com",
            "reasoning": True,
            "input": ["text", "image"],
            "cost": {
                "input": 3.0,
                "output": 15.0,
                "cache_read": 0.3,
                "cache_write": 3.75,
            },
            "context_window": 200000,
            "max_tokens": 64000,
        },
    },
    "openai": {
        "gpt-4o": {
            "id": "gpt-4o",
            "name": "GPT-4o",
            "api": "openai-completions",
            "provider": "openai",
            "base_url": "https://api.openai.com/v1",
            "reasoning": False,
            "input": ["text", "image"],
            "cost": {
                "input": 2.5,
                "output": 10.0,
                "cache_read": 1.25,
                "cache_write": 0.0,
            },
            "context_window": 128000,
            "max_tokens": 16384,
        },
        "gpt-4o-mini": {
            "id": "gpt-4o-mini",
            "name": "GPT-4o Mini",
            "api": "openai-completions",
            "provider": "openai",
            "base_url": "https://api.openai.com/v1",
            "reasoning": False,
            "input": ["text", "image"],
            "cost": {
                "input": 0.15,
                "output": 0.6,
                "cache_read": 0.075,
                "cache_write": 0.0,
            },
            "context_window": 128000,
            "max_tokens": 16384,
        },
        "o1": {
            "id": "o1",
            "name": "o1",
            "api": "openai-completions",
            "provider": "openai",
            "base_url": "https://api.openai.com/v1",
            "reasoning": True,
            "input": ["text", "image"],
            "cost": {
                "input": 15.0,
                "output": 60.0,
                "cache_read": 7.5,
                "cache_write": 0.0,
            },
            "context_window": 200000,
            "max_tokens": 100000,
        },
        "o1-mini": {
            "id": "o1-mini",
            "name": "o1 Mini",
            "api": "openai-completions",
            "provider": "openai",
            "base_url": "https://api.openai.com/v1",
            "reasoning": True,
            "input": ["text"],
            "cost": {
                "input": 3.0,
                "output": 12.0,
                "cache_read": 1.5,
                "cache_write": 0.0,
            },
            "context_window": 128000,
            "max_tokens": 65536,
        },
    },
    "google": {
        "gemini-2.5-flash-lite-preview-06-17": {
            "id": "gemini-2.5-flash-lite-preview-06-17",
            "name": "Gemini 2.5 Flash Lite",
            "api": "google-generative-ai",
            "provider": "google",
            "base_url": "https://generativelanguage.googleapis.com",
            "reasoning": False,
            "input": ["text", "image"],
            "cost": {
                "input": 0.0,
                "output": 0.0,
                "cache_read": 0.0,
                "cache_write": 0.0,
            },
            "context_window": 1000000,
            "max_tokens": 8192,
        },
        "gemini-2.0-flash": {
            "id": "gemini-2.0-flash",
            "name": "Gemini 2.0 Flash",
            "api": "google-generative-ai",
            "provider": "google",
            "base_url": "https://generativelanguage.googleapis.com",
            "reasoning": True,
            "input": ["text", "image"],
            "cost": {
                "input": 0.1,
                "output": 0.4,
                "cache_read": 0.025,
                "cache_write": 0.0,
            },
            "context_window": 1000000,
            "max_tokens": 8192,
        },
    },
    "groq": {
        "llama-3.3-70b-versatile": {
            "id": "llama-3.3-70b-versatile",
            "name": "Llama 3.3 70B",
            "api": "openai-completions",
            "provider": "groq",
            "base_url": "https://api.groq.com/openai/v1",
            "reasoning": False,
            "input": ["text"],
            "cost": {
                "input": 0.59,
                "output": 0.79,
                "cache_read": 0.0,
                "cache_write": 0.0,
            },
            "context_window": 128000,
            "max_tokens": 32768,
        },
    },
    "xai": {
        "grok-3": {
            "id": "grok-3",
            "name": "Grok 3",
            "api": "openai-completions",
            "provider": "xai",
            "base_url": "https://api.x.ai/v1",
            "reasoning": False,
            "input": ["text", "image"],
            "cost": {
                "input": 3.0,
                "output": 15.0,
                "cache_read": 0.0,
                "cache_write": 0.0,
            },
            "context_window": 131072,
            "max_tokens": 131072,
        },
    },
}
